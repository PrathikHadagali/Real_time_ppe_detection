{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02b9db8-feb4-4528-bae2-e28973a504f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in d:\\anaconda_24\\lib\\site-packages (8.2.22)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda_24\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda_24\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda_24\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda_24\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda_24\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda_24\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda_24\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda_24\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda_24\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda_24\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda_24\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda_24\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda_24\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda_24\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda_24\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda_24\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda_24\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e6f337-a670-477f-8f56-3b20b337d6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Masks, 1 NO-Safety Vest, 1 Person, 1018.9ms\n",
      "Speed: 3.5ms preprocess, 1018.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1104.8ms\n",
      "Speed: 4.2ms preprocess, 1104.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 974.6ms\n",
      "Speed: 0.0ms preprocess, 974.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1058.0ms\n",
      "Speed: 3.5ms preprocess, 1058.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 973.1ms\n",
      "Speed: 1.7ms preprocess, 973.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 996.5ms\n",
      "Speed: 0.0ms preprocess, 996.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1014.8ms\n",
      "Speed: 3.1ms preprocess, 1014.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Masks, 1 Person, 988.9ms\n",
      "Speed: 0.0ms preprocess, 988.9ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 Person, 963.5ms\n",
      "Speed: 3.6ms preprocess, 963.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 958.4ms\n",
      "Speed: 4.3ms preprocess, 958.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Masks, 1 Person, 977.8ms\n",
      "Speed: 6.2ms preprocess, 977.8ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 945.9ms\n",
      "Speed: 4.3ms preprocess, 945.9ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 942.9ms\n",
      "Speed: 6.3ms preprocess, 942.9ms inference, 1678.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 Person, 962.6ms\n",
      "Speed: 5.2ms preprocess, 962.6ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 967.8ms\n",
      "Speed: 5.6ms preprocess, 967.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 1198.1ms\n",
      "Speed: 4.1ms preprocess, 1198.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 3 NO-Masks, 1 NO-Safety Vest, 2 Persons, 992.9ms\n",
      "Speed: 5.0ms preprocess, 992.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 2 NO-Masks, 1 NO-Safety Vest, 1 Person, 953.8ms\n",
      "Speed: 5.5ms preprocess, 953.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 3 NO-Masks, 1 NO-Safety Vest, 2 Persons, 980.0ms\n",
      "Speed: 6.4ms preprocess, 980.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 NO-Hardhats, 2 NO-Masks, 1 NO-Safety Vest, 1 Person, 945.4ms\n",
      "Speed: 5.1ms preprocess, 945.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 NO-Hardhats, 2 NO-Masks, 1 NO-Safety Vest, 2 Persons, 1026.3ms\n",
      "Speed: 4.5ms preprocess, 1026.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 946.9ms\n",
      "Speed: 6.6ms preprocess, 946.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 3 Persons, 929.4ms\n",
      "Speed: 6.1ms preprocess, 929.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 1025.1ms\n",
      "Speed: 5.2ms preprocess, 1025.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 978.2ms\n",
      "Speed: 4.2ms preprocess, 978.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 959.4ms\n",
      "Speed: 5.7ms preprocess, 959.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Hardhat, 2 NO-Safety Vests, 2 Persons, 1034.0ms\n",
      "Speed: 5.6ms preprocess, 1034.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 942.8ms\n",
      "Speed: 5.2ms preprocess, 942.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 932.9ms\n",
      "Speed: 5.1ms preprocess, 932.9ms inference, 16.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 960.6ms\n",
      "Speed: 5.3ms preprocess, 960.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 Person, 868.0ms\n",
      "Speed: 5.0ms preprocess, 868.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 941.7ms\n",
      "Speed: 2.5ms preprocess, 941.7ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Safety Vest, 1 Person, 1007.7ms\n",
      "Speed: 5.2ms preprocess, 1007.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 1019.5ms\n",
      "Speed: 0.0ms preprocess, 1019.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 1080.6ms\n",
      "Speed: 4.3ms preprocess, 1080.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Hardhat, 2 NO-Masks, 1 NO-Safety Vest, 2 Persons, 946.6ms\n",
      "Speed: 5.2ms preprocess, 946.6ms inference, 9.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 2 Persons, 973.0ms\n",
      "Speed: 4.9ms preprocess, 973.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Hardhat, 1 NO-Safety Vest, 3 Persons, 919.8ms\n",
      "Speed: 0.0ms preprocess, 919.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 1003.6ms\n",
      "Speed: 0.0ms preprocess, 1003.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 963.9ms\n",
      "Speed: 4.7ms preprocess, 963.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 895.3ms\n",
      "Speed: 3.5ms preprocess, 895.3ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 935.6ms\n",
      "Speed: 0.0ms preprocess, 935.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Hardhat, 2 NO-Masks, 1 NO-Safety Vest, 2 Persons, 949.3ms\n",
      "Speed: 3.8ms preprocess, 949.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 922.7ms\n",
      "Speed: 2.9ms preprocess, 922.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Hardhat, 1 NO-Hardhat, 2 NO-Masks, 1 NO-Safety Vest, 2 Persons, 907.1ms\n",
      "Speed: 3.7ms preprocess, 907.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 887.4ms\n",
      "Speed: 3.0ms preprocess, 887.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 964.5ms\n",
      "Speed: 2.0ms preprocess, 964.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 936.4ms\n",
      "Speed: 3.1ms preprocess, 936.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Safety Vest, 2 Persons, 914.9ms\n",
      "Speed: 0.0ms preprocess, 914.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 1025.1ms\n",
      "Speed: 0.0ms preprocess, 1025.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Safety Vest, 1 Person, 1012.1ms\n",
      "Speed: 4.4ms preprocess, 1012.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Safety Vest, 1 Person, 969.7ms\n",
      "Speed: 0.0ms preprocess, 969.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Safety Vest, 1 Person, 1000.1ms\n",
      "Speed: 3.5ms preprocess, 1000.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 983.5ms\n",
      "Speed: 3.2ms preprocess, 983.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 986.2ms\n",
      "Speed: 4.2ms preprocess, 986.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 1018.5ms\n",
      "Speed: 3.6ms preprocess, 1018.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 1012.5ms\n",
      "Speed: 5.3ms preprocess, 1012.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 972.0ms\n",
      "Speed: 0.0ms preprocess, 972.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1144.1ms\n",
      "Speed: 6.0ms preprocess, 1144.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1013.3ms\n",
      "Speed: 4.2ms preprocess, 1013.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 973.5ms\n",
      "Speed: 0.0ms preprocess, 973.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 983.1ms\n",
      "Speed: 4.6ms preprocess, 983.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 980.9ms\n",
      "Speed: 4.6ms preprocess, 980.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1045.5ms\n",
      "Speed: 4.1ms preprocess, 1045.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Safety Vest, 1 Person, 934.2ms\n",
      "Speed: 4.3ms preprocess, 934.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Safety Vests, 2 Persons, 983.8ms\n",
      "Speed: 5.3ms preprocess, 983.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 941.7ms\n",
      "Speed: 4.0ms preprocess, 941.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Safety Vests, 2 Persons, 1026.3ms\n",
      "Speed: 5.1ms preprocess, 1026.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 4 NO-Safety Vests, 3 Persons, 986.6ms\n",
      "Speed: 4.5ms preprocess, 986.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 2 NO-Safety Vests, 3 Persons, 1009.2ms\n",
      "Speed: 0.0ms preprocess, 1009.2ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 2 Persons, 996.0ms\n",
      "Speed: 4.9ms preprocess, 996.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 NO-Hardhats, 2 NO-Masks, 2 NO-Safety Vests, 4 Persons, 977.2ms\n",
      "Speed: 4.1ms preprocess, 977.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Masks, 1 NO-Hardhat, 1 NO-Mask, 2 NO-Safety Vests, 2 Persons, 1009.7ms\n",
      "Speed: 2.6ms preprocess, 1009.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 2 NO-Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 2 Persons, 1013.5ms\n",
      "Speed: 4.9ms preprocess, 1013.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 2 NO-Safety Vests, 2 Persons, 991.2ms\n",
      "Speed: 0.0ms preprocess, 991.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 3 NO-Hardhats, 2 NO-Masks, 2 NO-Safety Vests, 3 Persons, 981.3ms\n",
      "Speed: 5.1ms preprocess, 981.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 NO-Hardhats, 2 NO-Masks, 2 NO-Safety Vests, 2 Persons, 1046.5ms\n",
      "Speed: 2.8ms preprocess, 1046.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Masks, 2 NO-Safety Vests, 4 Persons, 992.5ms\n",
      "Speed: 4.2ms preprocess, 992.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 2 NO-Masks, 2 NO-Safety Vests, 4 Persons, 1001.4ms\n",
      "Speed: 4.7ms preprocess, 1001.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 NO-Hardhats, 2 NO-Masks, 2 NO-Safety Vests, 2 Persons, 1042.6ms\n",
      "Speed: 4.4ms preprocess, 1042.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Masks, 3 NO-Safety Vests, 2 Persons, 1010.3ms\n",
      "Speed: 0.0ms preprocess, 1010.3ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 2 NO-Safety Vests, 3 Persons, 1082.7ms\n",
      "Speed: 2.8ms preprocess, 1082.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"best.pt\")\n",
    "names = model.model.names\n",
    "\n",
    "def stream_video():\n",
    "    # Open a connection to the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if the webcam is opened correctly\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video device.\")\n",
    "        return\n",
    "\n",
    "    # Set video frame dimensions (optional)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    # Stream video until the user terminates the code\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        # Pass the frame to the YOLOv8 model\n",
    "        results = model(frame)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        clss = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "        # Annotator Init\n",
    "        annotator = Annotator(frame, line_width=2)\n",
    "\n",
    "        for box, cls in zip(boxes, clss):\n",
    "            annotator.box_label(box, color=colors(int(cls), True), label=names[int(cls)])\n",
    "\n",
    "        # Display the resulting frame with detections\n",
    "        annotated_frame = annotator.result()\n",
    "        cv2.imshow('Video Stream with YOLOv8', annotated_frame)\n",
    "\n",
    "        # Press 'q' to quit the video stream\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture when everything is done\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "stream_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b63716-b141-4f63-b7fb-0df4e8186ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from ultralytics.utils.checks import check_imshow\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "track_history = defaultdict(lambda: [])\n",
    "model = YOLO(\"best.pt\")\n",
    "names = model.model.names\n",
    "\n",
    "video_path = \"prathik.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "result = cv2.VideoWriter(\"object_tracking.avi\",\n",
    "                       cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                       fps,\n",
    "                       (w, h))\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        results = model.track(frame, persist=True, verbose=False)\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "\n",
    "            # Extract prediction results\n",
    "            clss = results[0].boxes.cls.cpu().tolist()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "            confs = results[0].boxes.conf.float().cpu().tolist()\n",
    "\n",
    "            # Annotator Init\n",
    "            annotator = Annotator(frame, line_width=2)\n",
    "\n",
    "            for box, cls, track_id in zip(boxes, clss, track_ids):\n",
    "                annotator.box_label(box, color=colors(int(cls), True), label=names[int(cls)])\n",
    "\n",
    "                # Store tracking history\n",
    "                track = track_history[track_id]\n",
    "                track.append((int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2)))\n",
    "                if len(track) > 30:\n",
    "                    track.pop(0)\n",
    "\n",
    "                # Plot tracks\n",
    "                points = np.array(track, dtype=np.int32).reshape((-1, 1, 2))\n",
    "                cv2.circle(frame, (track[-1]), 7, colors(int(cls), True), -1)\n",
    "                cv2.polylines(frame, [points], isClosed=False, color=colors(int(cls), True), thickness=2)\n",
    "\n",
    "        result.write(frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "result.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fc6b28-c205-4e87-b48e-5c20b50ae086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert avi to mp4 and save in folder \n",
    "import cv2\n",
    "\n",
    "# Replace 'your_video.avi' with the actual filename\n",
    "cap = cv2.VideoCapture('object_tracking.avi')\n",
    "\n",
    "# Define the output filename (e.g., converted_video.mp4)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('converted_video.mp4', fourcc, 20.0, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process or display the frame here (optional)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb978b7a-3a2d-4852-9d8f-112e821d967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    " \n",
    " \n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('converted_video.mp4')\n",
    " \n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "  print(\"Error opening video stream or file\")\n",
    " \n",
    "# Read until video is completed\n",
    "while (cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    " \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame', frame)\n",
    " \n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    # Break the loop\n",
    "    else:\n",
    "        break\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339e514-4caa-487a-a99e-a86757b75ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
